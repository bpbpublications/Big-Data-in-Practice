{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCiHakzM3bXEcE1iwVIWjF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RHIV4mDL_1e","executionInfo":{"status":"ok","timestamp":1765251513180,"user_tz":360,"elapsed":22955,"user":{"displayName":"Jiten J","userId":"02347952651290083373"}},"outputId":"54e01342-0869-4b0c-87d5-a379990f81d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n","Original RDD:\n","[1, 2, 3, 4, 5]\n","After map (x * 2):\n","[2, 4, 6, 8, 10]\n","After filter (values > 5):\n","[6, 8, 10]\n","Sum of filtered elements: 24\n"]}],"source":["# Install PySpark in Colab\n","!pip install pyspark\n","\n","from pyspark import SparkContext\n","\n","# Create a SparkContext\n","sc = SparkContext.getOrCreate()\n","\n","# Create an RDD from a Python list\n","data = [1, 2, 3, 4, 5]\n","rdd = sc.parallelize(data)\n","\n","print(\"Original RDD:\")\n","print(rdd.collect())\n","\n","# Apply transformations\n","rdd_mapped = rdd.map(lambda x: x * 2)\n","rdd_filtered = rdd_mapped.filter(lambda x: x > 5)\n","\n","print(\"After map (x * 2):\")\n","print(rdd_mapped.collect())\n","\n","print(\"After filter (values > 5):\")\n","print(rdd_filtered.collect())\n","\n","# Apply an action\n","sum_value = rdd_filtered.reduce(lambda a, b: a + b)\n","print(\"Sum of filtered elements:\", sum_value)\n","\n","# Stop the context if needed\n","sc.stop()\n"]}]}